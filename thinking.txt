What I am having in mind is temorarily not to use GCN or any graph-based model, but simply plot (translate) the extracted (detected) graph into a fixed-sized picture. And use CNN to process this picture. 

Or, more directly, first ignore the graph structure of the hand and just concatenate all the 21 landmarks together to get a 21 x 3 (?) matrix {or more likely similar to our last work, a vector of the 21 landmarks}. Then simply use Linear layers to (perhaps Residual Blocks) to transform the vector into a smaller vector that we think can grasp the core features of handshapes. 



!!!Problem: 
the data is having quite a lot without obvious hs. These mainly come from interpolated data, probably we should ignore them for better data quality. The way to ignore them is: ignore all those frames that are interpolated. 






1. The reason I did not get the handshape chart is because the pdf file's handshape font is not rendered as picture. Therefore, since my computer does not have the CUHK HKSL HS font, it won't show. I installed it and it works. 
2. Out of the 981 entries, 767 are monomorphemic. Out of these only 159 are bimanual and heteromorphic. Not all are dextrous (=DH is right hand) but it almost. 


nique that we might try is shifting the graph: i.e. move the positions around the space. Just make sure they stay wTo enlarge our dataset, one enhancement techithin the frame and everything could be shifted. 


The strange problem if we separate training and validation datasets it cannot learn, but when on one dataset and separated it performs well. 
My guess is that if we have two datasets something is totally different from having two subsets of one dataset. 
Therefore, we will consider using the same technique used in wavln for saving separation so that when plotting results we can avoid having those trained. 
But for shrinking frame we have to do that outside of dataset, like before feeding data into model. 