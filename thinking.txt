What I am having in mind is temorarily not to use GCN or any graph-based model, but simply plot (translate) the extracted (detected) graph into a fixed-sized picture. And use CNN to process this picture. 

Or, more directly, first ignore the graph structure of the hand and just concatenate all the 21 landmarks together to get a 21 x 3 (?) matrix {or more likely similar to our last work, a vector of the 21 landmarks}. Then simply use Linear layers to (perhaps Residual Blocks) to transform the vector into a smaller vector that we think can grasp the core features of handshapes. 



!!!Problem: 
the data is having quite a lot without obvious hs. These mainly come from interpolated data, probably we should ignore them for better data quality. The way to ignore them is: ignore all those frames that are interpolated. 






1. The reason I did not get the handshape chart is because the pdf file's handshape font is not rendered as picture. Therefore, since my computer does not have the CUHK HKSL HS font, it won't show. I installed it and it works. 
2. Out of the 981 entries, 767 are monomorphemic. Out of these only 159 are bimanual and heteromorphic. Not all are dextrous (=DH is right hand) but it almost. 


To enlarge our dataset, one enhancement technique that we might try is shifting the graph: i.e. move the positions around the space. Just make sure they stay within the frame and everything could be shifted. 