{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model try\n",
    "V1.0  \n",
    "This version is a first build-up of the whole system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_dataset import HandshapeDataset, HandshapeDict\n",
    "from paths import *\n",
    "from model_model import HandshapePredictor\n",
    "from model_configs import *\n",
    "from utils import *\n",
    "from recorder import *\n",
    "from graph_tools import GraphTool, Plotter, Smoother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = HandshapePredictor(\n",
    "    input_dim=in_dim, \n",
    "    enc_lat_dims=enc_lat_dims, \n",
    "    hid_dim=hid_dim, \n",
    "    dec_lat_dims=dec_lat_dims, \n",
    "    output_dim=out_dim\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HandshapePredictor(\n",
       "  (encoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=63, out_features=32, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (lin1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): LinPack(\n",
       "      (lin): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (lin1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Linear(in_features=16, out_features=5, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=5, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): LinPack(\n",
       "      (lin): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=32, out_features=93, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just for keeping records of training hists. \n",
    "# ts = str(get_timestamp())\n",
    "# # ts = \"0623152604\"\n",
    "# save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "# save_trainhist_name = \"train_{}.hst\".format(ts)\n",
    "# save_valhist_name = \"val_{}.hst\".format(ts)\n",
    "# save_valacc_name = \"valacc{}.hst\".format(ts)\n",
    "\n",
    "# valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "# train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "# valid_accuracies = LossRecorder(model_save_dir + save_valacc_name)\n",
    "# text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ = False\n",
    "READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if READ: \n",
    "    # model_name = last_model_namec\n",
    "    model_name = \"PT_0816115032_1799_full.pt\"\n",
    "    # model_name = \"PT_0816184446_1349_full.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "css_in = \"\"\"\n",
    "<head>\n",
    "    <link rel=\"stylesheet\" href=\"{}\">\n",
    "</head>\n",
    "\"\"\".format(outstyle_path)\n",
    "\n",
    "control_script_pre = \"\"\"\n",
    "<script>\n",
    "const integerInput = document.getElementById('integerInput');\n",
    "const outputDiv = document.getElementById('outputDiv');\n",
    "\n",
    "const stringsList =\"\"\"\n",
    "\n",
    "control_script_post = \"\"\"\n",
    "integerInput.addEventListener('input', () => {\n",
    "  const selectedIndex = parseInt(integerInput.value);\n",
    "  \n",
    "  if (selectedIndex >= 0 && selectedIndex < stringsList.length) {\n",
    "    const selectedString = stringsList[selectedIndex];\n",
    "    outputDiv.textContent = selectedString;\n",
    "  } else {\n",
    "    outputDiv.textContent = \"ç„¡\";\n",
    "  }\n",
    "});\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "frame_pred_vis = \"\"\"\n",
    "<div class=\"container\">\n",
    "  <input type=\"number\" id=\"integerInput\" min=\"0\">\n",
    "  <div class=\"output\" id=\"outputDiv\"></div>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HKSL_lesson_only465-WHEELCHAIR-13PA-943\n",
      "HKSL_lesson_only466-BLIND-0TNI-944\n",
      "HKSL_lesson_only467-DISABLED_PERSON-0QSO-945\n",
      "HKSL_lesson_only468-FIRST_AID-0O15-946\n",
      "HKSL_lesson_only469-RESCUE-0ONF-947\n",
      "HKSL_lesson_only47-YESTERDAY-0PH8-509\n",
      "HKSL_lesson_only470-HOSPITALIZE-1401-948\n",
      "HKSL_lesson_only471-SURGERY-0OIB-949\n",
      "HKSL_lesson_only472-CANCER-0TIC-950\n",
      "HKSL_lesson_only473-FEVER-0TJS-951\n",
      "HKSL_lesson_only474-RECOVER-0NLN-952\n",
      "HKSL_lesson_only475-SHY-0MTJ-953\n",
      "HKSL_lesson_only476-BLUSHING-15R2-954\n",
      "HKSL_lesson_only477-PALE_FACED-15R2-955\n",
      "HKSL_lesson_only478-SCARED-0MTJ-956\n",
      "HKSL_lesson_only479-SCARY-0O2G-957\n",
      "HKSL_lesson_only48-TOMORROW-0PGE-510\n",
      "HKSL_lesson_only480-GREEDY-135A-958\n",
      "HKSL_lesson_only480-^GREEDY_2-135A-959\n",
      "HKSL_lesson_only481-STINGY-0MR4-960\n",
      "HKSL_lesson_only482-PETTY-0N0F-961\n",
      "HKSL_lesson_only483-GRUDGEFUL-12GO-962\n",
      "HKSL_lesson_only484-LUSTFUL-0MBT-963\n",
      "HKSL_lesson_only485-WIDE_EYED-0TPS-964\n",
      "HKSL_lesson_only486-POINTLESS-0S91-965\n",
      "HKSL_lesson_only487-JEALOUS_IN_LOVE-0L3N-968\n",
      "HKSL_lesson_only487-^JEALOUS-0MM9-966\n",
      "HKSL_lesson_only488-UNEXPECTED-0KFQ-967\n",
      "HKSL_lesson_only489-ASKING_FOR_TROUBLE-10FA-969\n",
      "HKSL_lesson_only49-MONTH-0JG0-511\n",
      "HKSL_lesson_only490-HILARIOUS-0P0U-970\n",
      "HKSL_lesson_only491-MOLEITAU-0S91-971\n",
      "HKSL_lesson_only492-JOKING-0ST9-972\n",
      "HKSL_lesson_only493-TOUCHING-0O8V-973\n",
      "HKSL_lesson_only494-ENGROSSED-0OKL-974\n",
      "HKSL_lesson_only495-ANTICIPATING-0POV-975\n",
      "HKSL_lesson_only496-INSTINCT-0TNK-976\n",
      "HKSL_lesson_only497-TOIL-0ORH-977\n",
      "HKSL_lesson_only498-UNAFRAID-0JGD-978\n",
      "HKSL_lesson_only499-REGRETFUL-0NSC-979\n",
      "HKSL_lesson_only5-HEARING-0K35-463\n",
      "HKSL_lesson_only50-HOW_MANY-0NJU-512\n",
      "HKSL_lesson_only51-BIRTHDAY-0T8V-513\n",
      "HKSL_lesson_only52-LUNAR_CALENDAR-13TI-514\n",
      "HKSL_lesson_only53-NEW_YEAR-0PDG-515\n",
      "HKSL_lesson_only54-DRAGON_BOAT_FESTIVAL-0UNF-516\n",
      "HKSL_lesson_only55-VALENTINES_DAY-0O65-517\n",
      "HKSL_lesson_only56-EASTER-0NT9-518\n",
      "HKSL_lesson_only57-MID_AUTUMN_FESTIVAL-0JHD-519\n",
      "HKSL_lesson_only58-TOMB_SWEEPING_DAY-0RG5-520\n",
      "HKSL_lesson_only59-CHRISTMAS-102M-521\n",
      "HKSL_lesson_only6-HARD_OF_HEARING-0NPH-464\n",
      "HKSL_lesson_only60-IDLE-0NSN-522\n",
      "HKSL_lesson_only61-BUSY-0NUP-523\n",
      "HKSL_lesson_only62-PHOTOGRAPH-0P8T-524\n",
      "HKSL_lesson_only62-^PHOTOGRAPH_2-0P8T-525\n",
      "HKSL_lesson_only63-DRAW-0VJA-526\n",
      "HKSL_lesson_only64-WANDER-140R-527\n",
      "HKSL_lesson_only65-SHOPPING-137S-528\n",
      "HKSL_lesson_only66-HIKE-122C-529\n",
      "HKSL_lesson_only67-BICYCLE-0LDE-530\n",
      "HKSL_lesson_only68-BOAT_TRIP-142A-531\n",
      "HKSL_lesson_only69-TENNIS-0VDI-532\n",
      "HKSL_lesson_only7-DONT_UNDERSTAND-0JGD-465\n",
      "HKSL_lesson_only70-SQUASH-0M61-533\n",
      "HKSL_lesson_only71-BADMINTON-0VTT-534\n",
      "HKSL_lesson_only72-VOLLEYBALL-0OSI-535\n",
      "HKSL_lesson_only73-BOWLING-0JUT-536\n",
      "HKSL_lesson_only74-FOOTBALL_SOCCER-13DJ-537\n",
      "HKSL_lesson_only75-ICESKATING-0RKS-538\n",
      "HKSL_lesson_only76-SWIM-0RHO-539\n",
      "HKSL_lesson_only77-SCUBA_DIVING-0RQR-540\n",
      "HKSL_lesson_only78-DIVE-13FJ-541\n",
      "HKSL_lesson_only79-WALK-13BG-542\n",
      "HKSL_lesson_only8-AGAIN-0KCD-466\n",
      "HKSL_lesson_only80-READ-15DH-543\n",
      "HKSL_lesson_only81-LISTEN_TO_MUSIC-103T-544\n",
      "HKSL_lesson_only82-PLAY_VIDEO_GAME-0ST9-545\n",
      "HKSL_lesson_only83-BARBECUE-0SEI-546\n",
      "HKSL_lesson_only84-CAMP-15PI-547\n",
      "HKSL_lesson_only85-ACTIVITIES-0R9R-548\n",
      "HKSL_lesson_only86-ALL_KINDS-0L04-549\n",
      "HKSL_lesson_only87-TO_LIKE-0LCS-550\n",
      "HKSL_lesson_only88-DISLIKE-0JGD-551\n",
      "HKSL_lesson_only89-WHY-0S5Q-552\n",
      "HKSL_lesson_only9-THANK_YOU-12OT-467\n",
      "HKSL_lesson_only90-FLOWER-10LH-553\n",
      "HKSL_lesson_only91-GRASS-10Q9-554\n",
      "HKSL_lesson_only92-TREE-0QHP-555\n",
      "HKSL_lesson_only93-WOOD-0PP8-556\n",
      "HKSL_lesson_only94-MOUNTAIN-0N3H-557\n",
      "HKSL_lesson_only95-LEAF-1129-558\n",
      "HKSL_lesson_only96-CLOUD-15NI-559\n",
      "HKSL_lesson_only96-^CLOUD_2-15NI-560\n",
      "HKSL_lesson_only97-RAIN-15N8-561\n",
      "HKSL_lesson_only98-LIGHTNING-15C3-562\n",
      "HKSL_lesson_only99-RAINBOW-0NR9-563\n",
      "NULL-^LISTEN-103T-336\n"
     ]
    }
   ],
   "source": [
    "file_prefix = \"cynthia_data\"\n",
    "tag_path = os.path.join(data_dir, file_prefix + \"_tag.npz\")\n",
    "hsdict = HandshapeDict(tag_path)\n",
    "\n",
    "for vd in os.listdir(det_dir): \n",
    "    for clip in os.listdir(det_dir + vd + \"/\")[876:]: \n",
    "        print(clip)\n",
    "        for whether_smooth in [\"non\", \"ma\"]: \n",
    "            smooth_dir = os.path.join(spec_dir, whether_smooth + \"/\")\n",
    "            pic_smooth_dir = os.path.join(spec_pic_dir, whether_smooth + \"/\")\n",
    "            mk(smooth_dir)\n",
    "            mk(pic_smooth_dir)\n",
    "\n",
    "            for side in [\"Right\", \"Left\"]:\n",
    "                find_name = \"{}_{}\".format(side, clip)\n",
    "                reverse_find_name = \"{}_{}\".format(clip, side)\n",
    "\n",
    "                gt = GraphTool(graph_dir, find_name)\n",
    "                gt.interpolate(window_size=2)\n",
    "\n",
    "                if whether_smooth == \"non\": \n",
    "                    smoothed_features = gt.interpolated_features\n",
    "                elif whether_smooth == \"ma\": \n",
    "                    smoothed_features = Smoother.moving_average(gt.interpolated_features)\n",
    "                else: \n",
    "                    smoothed_features = gt.interpolated_features\n",
    "\n",
    "                this_features = torch.from_numpy(smoothed_features.copy())\n",
    "                batch_num, lm_num, dim_num = this_features.size()\n",
    "\n",
    "                x = this_features\n",
    "                x = x.to(device)\n",
    "                x = x.to(torch.float32)\n",
    "\n",
    "                hid_rep, pred = model.predict(x, hsdict)\n",
    "\n",
    "                hid_rep = hid_rep.cpu().detach().numpy()\n",
    "\n",
    "                html = \"\"\"\"\"\"\n",
    "\n",
    "                html += css_in\n",
    "\n",
    "                html += \"\"\"<h1>{}</h1><br>\"\"\".format(reverse_find_name)\n",
    "\n",
    "                html += frame_pred_vis\n",
    "\n",
    "                html += Plotter.plot_spectrogram(\n",
    "                    hid_rep, \n",
    "                    title=\"ML Spectrogram\" + side, \n",
    "                    save_path= os.path.join(pic_smooth_dir, reverse_find_name + \"_mlspec\")\n",
    "                )\n",
    "\n",
    "                html += Plotter.plot_line_graph(hid_rep, [\"0\", \"1\", \"2\", \"3\", \"4\"], \n",
    "                                                \"ML Linegraph\" + side, y_axis_label=\"Val\", \n",
    "                                                save_path= os.path.join(pic_smooth_dir, reverse_find_name + \"_mlline\"))\n",
    "                \n",
    "                html += control_script_pre + str(pred) + control_script_post\n",
    "                \n",
    "                Plotter.write_to_html(html, \"{}{}.html\".format(smooth_dir, reverse_find_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slprt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
